{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve previously stored variables from Part 1 of CNN notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(954, 40, 182)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve previously stored variables\n",
    "%store -r x_train\n",
    "%store -r x_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "%store -r yy\n",
    "%store -r le\n",
    "%store -r max_pad_length\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = max_pad_length\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "\n",
    "# Construct CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Increasing nodes from 16, 32, 64, 128\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Output based on number of category labels\n",
    "# softmax is used as the output layer to make the output sum up to 1 -> can be used to interpret as probabilities\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complilation of Archituecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# Optimizer \"adam\" is a typical optimizer used- variation SGD (stochastic gradient descent)\n",
    "# Optimizer controls the learning rate\n",
    "# SGD utilizes the gradient of the loss function with respects to the weight\n",
    "# loss -> typical loss function \n",
    "# metrics is output to be displayed (accuracy is the output of the loss function (?))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Model Architecture \n",
    "##### Test accuracy of model with no training - random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 181, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 90, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 89, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 44, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 44, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 43, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 21, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 21, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 10, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1, 10, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 43,699\n",
      "Trainable params: 43,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 35.5346%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.38174973493852, 0.3553459048271179]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "# Verbose - displays info if desired (verbose = 0 means silent, just print accuracy value)\n",
    "# evaluate returns loss value and score value\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Accuracy - the metrics value evaluated based on loss function\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 954 samples, validate on 318 samples\n",
      "Epoch 1/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 1.5602 - accuracy: 0.6258 - val_loss: 0.4883 - val_accuracy: 0.8113\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.48827, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 2/150\n",
      "954/954 [==============================] - 5s 5ms/step - loss: 0.4687 - accuracy: 0.8312 - val_loss: 0.5672 - val_accuracy: 0.7547\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.48827\n",
      "Epoch 3/150\n",
      "954/954 [==============================] - 5s 5ms/step - loss: 0.4086 - accuracy: 0.8417 - val_loss: 0.3011 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48827 to 0.30107, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 4/150\n",
      "954/954 [==============================] - 5s 5ms/step - loss: 0.3098 - accuracy: 0.8711 - val_loss: 0.2721 - val_accuracy: 0.9025\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.30107 to 0.27209, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 5/150\n",
      "954/954 [==============================] - 5s 5ms/step - loss: 0.2522 - accuracy: 0.9046 - val_loss: 0.3433 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27209\n",
      "Epoch 6/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.2798 - accuracy: 0.9078 - val_loss: 0.2534 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27209 to 0.25341, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 7/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.2298 - accuracy: 0.9172 - val_loss: 0.2226 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25341 to 0.22256, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 8/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.1839 - accuracy: 0.9340 - val_loss: 0.2851 - val_accuracy: 0.8962\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22256\n",
      "Epoch 9/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.2108 - accuracy: 0.9340 - val_loss: 0.2015 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22256 to 0.20151, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 10/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.1848 - accuracy: 0.9455 - val_loss: 0.1438 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20151 to 0.14376, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 11/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1617 - accuracy: 0.9497 - val_loss: 0.1724 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.14376\n",
      "Epoch 12/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1776 - accuracy: 0.9497 - val_loss: 0.1541 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.14376\n",
      "Epoch 13/150\n",
      "954/954 [==============================] - 5s 5ms/step - loss: 0.1159 - accuracy: 0.9633 - val_loss: 0.1598 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.14376\n",
      "Epoch 14/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.1737 - accuracy: 0.9444 - val_loss: 0.1901 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.14376\n",
      "Epoch 15/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1934 - accuracy: 0.9361 - val_loss: 0.1554 - val_accuracy: 0.9623\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.14376\n",
      "Epoch 16/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1137 - accuracy: 0.9644 - val_loss: 0.1385 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.14376 to 0.13845, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 17/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1261 - accuracy: 0.9665 - val_loss: 0.2692 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.13845\n",
      "Epoch 18/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.1281 - accuracy: 0.9623 - val_loss: 0.1334 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.13845 to 0.13341, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 19/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0878 - accuracy: 0.9727 - val_loss: 0.1207 - val_accuracy: 0.9591\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.13341 to 0.12074, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 20/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1049 - accuracy: 0.9706 - val_loss: 0.1081 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.12074 to 0.10812, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 21/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0886 - accuracy: 0.9696 - val_loss: 0.1793 - val_accuracy: 0.9403\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.10812\n",
      "Epoch 22/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0994 - accuracy: 0.9769 - val_loss: 0.1040 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.10812 to 0.10402, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 23/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.0612 - accuracy: 0.9811 - val_loss: 0.1169 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10402\n",
      "Epoch 24/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1535 - accuracy: 0.9549 - val_loss: 0.1124 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.10402\n",
      "Epoch 25/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1247 - accuracy: 0.9591 - val_loss: 0.1248 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.10402\n",
      "Epoch 26/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0873 - accuracy: 0.9780 - val_loss: 0.0910 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.10402 to 0.09096, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 27/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0695 - accuracy: 0.9811 - val_loss: 0.0958 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09096\n",
      "Epoch 28/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 0.0988 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.09096\n",
      "Epoch 29/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.1240 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.09096\n",
      "Epoch 30/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 0.1108 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.09096\n",
      "Epoch 31/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1099 - accuracy: 0.9528 - val_loss: 0.1079 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.09096\n",
      "Epoch 32/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0653 - accuracy: 0.9832 - val_loss: 0.1254 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09096\n",
      "Epoch 33/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.0974 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.09096\n",
      "Epoch 34/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0713 - accuracy: 0.9727 - val_loss: 0.0845 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.09096 to 0.08448, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 35/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0575 - accuracy: 0.9790 - val_loss: 0.1135 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.08448\n",
      "Epoch 36/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0701 - accuracy: 0.9853 - val_loss: 0.0982 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.08448\n",
      "Epoch 37/150\n",
      "954/954 [==============================] - 5s 6ms/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.1092 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.08448\n",
      "Epoch 38/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0290 - accuracy: 0.9895 - val_loss: 0.1013 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.08448\n",
      "Epoch 39/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0732 - accuracy: 0.9769 - val_loss: 0.1017 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08448\n",
      "Epoch 40/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0456 - accuracy: 0.9780 - val_loss: 0.0985 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.08448\n",
      "Epoch 41/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0467 - accuracy: 0.9874 - val_loss: 0.1355 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08448\n",
      "Epoch 42/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0311 - accuracy: 0.9948 - val_loss: 0.1072 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08448\n",
      "Epoch 43/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0645 - accuracy: 0.9780 - val_loss: 0.1008 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.08448\n",
      "Epoch 44/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0713 - accuracy: 0.9822 - val_loss: 0.1490 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.08448\n",
      "Epoch 45/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0791 - accuracy: 0.9759 - val_loss: 0.1004 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.08448\n",
      "Epoch 46/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0436 - accuracy: 0.9885 - val_loss: 0.0809 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08448 to 0.08094, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 47/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.0824 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.08094\n",
      "Epoch 48/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0878 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08094\n",
      "Epoch 49/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.1297 - accuracy: 0.9675 - val_loss: 0.3381 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08094\n",
      "Epoch 50/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 0.0844 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.08094\n",
      "Epoch 51/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0792 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08094 to 0.07921, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 52/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.0931 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.07921\n",
      "Epoch 53/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0267 - accuracy: 0.9927 - val_loss: 0.0924 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.07921\n",
      "Epoch 54/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0661 - accuracy: 0.9811 - val_loss: 0.2826 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.07921\n",
      "Epoch 55/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.2734 - accuracy: 0.9486 - val_loss: 0.1498 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.07921\n",
      "Epoch 56/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0615 - accuracy: 0.9780 - val_loss: 0.0766 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07921 to 0.07655, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 57/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0339 - accuracy: 0.9895 - val_loss: 0.0799 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.07655\n",
      "Epoch 58/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.1186 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07655\n",
      "Epoch 59/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0328 - accuracy: 0.9916 - val_loss: 0.0723 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.07655 to 0.07230, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 60/150\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.0374 - accuracy: 0.9822 - val_loss: 0.1017 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.07230\n",
      "Epoch 61/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0353 - accuracy: 0.9874 - val_loss: 0.1074 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07230\n",
      "Epoch 62/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0260 - accuracy: 0.9874 - val_loss: 0.1018 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07230\n",
      "Epoch 63/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.1139 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07230\n",
      "Epoch 64/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.1125 - accuracy: 0.9706 - val_loss: 0.1138 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.07230\n",
      "Epoch 65/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0692 - accuracy: 0.9811 - val_loss: 0.1113 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07230\n",
      "Epoch 66/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.1060 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.07230\n",
      "Epoch 67/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.0901 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07230\n",
      "Epoch 68/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0306 - accuracy: 0.9927 - val_loss: 0.1212 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.07230\n",
      "Epoch 69/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0238 - accuracy: 0.9906 - val_loss: 0.1048 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.07230\n",
      "Epoch 70/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 0.1050 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.07230\n",
      "Epoch 71/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.1212 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.07230\n",
      "Epoch 72/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0474 - accuracy: 0.9843 - val_loss: 0.2103 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.07230\n",
      "Epoch 73/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.1196 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.07230\n",
      "Epoch 74/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0199 - accuracy: 0.9906 - val_loss: 0.1113 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.07230\n",
      "Epoch 75/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.1143 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.07230\n",
      "Epoch 76/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.1233 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.07230\n",
      "Epoch 77/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.0879 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.07230\n",
      "Epoch 78/150\n",
      "954/954 [==============================] - 6s 6ms/step - loss: 0.0651 - accuracy: 0.9811 - val_loss: 0.1178 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.07230\n",
      "Epoch 79/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.1152 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.07230\n",
      "Epoch 80/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.1262 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.07230\n",
      "Epoch 81/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.1048 - accuracy: 0.9696 - val_loss: 0.1329 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.07230\n",
      "Epoch 82/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0416 - accuracy: 0.9853 - val_loss: 0.1327 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.07230\n",
      "Epoch 83/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.0863 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.07230\n",
      "Epoch 84/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0274 - accuracy: 0.9885 - val_loss: 0.1146 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.07230\n",
      "Epoch 85/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0481 - accuracy: 0.9895 - val_loss: 0.0956 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.07230\n",
      "Epoch 86/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0247 - accuracy: 0.9895 - val_loss: 0.1238 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.07230\n",
      "Epoch 87/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.1215 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.07230\n",
      "Epoch 88/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.1211 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.07230\n",
      "Epoch 89/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1193 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.07230\n",
      "Epoch 90/150\n",
      "954/954 [==============================] - 8s 8ms/step - loss: 0.0252 - accuracy: 0.9895 - val_loss: 0.0486 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.07230 to 0.04855, saving model to saved_models/weights.best.basic_mlp.hdf5\n",
      "Epoch 91/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0566 - accuracy: 0.9843 - val_loss: 0.2113 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04855\n",
      "Epoch 92/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0396 - accuracy: 0.9885 - val_loss: 0.1179 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.04855\n",
      "Epoch 93/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.1006 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04855\n",
      "Epoch 94/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0114 - accuracy: 0.9937 - val_loss: 0.1108 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04855\n",
      "Epoch 95/150\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.1110 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04855\n",
      "Epoch 96/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.1279 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04855\n",
      "Epoch 97/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0322 - accuracy: 0.9853 - val_loss: 0.1697 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04855\n",
      "Epoch 98/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0558 - accuracy: 0.9885 - val_loss: 0.0810 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04855\n",
      "Epoch 99/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0751 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04855\n",
      "Epoch 100/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0259 - accuracy: 0.9885 - val_loss: 0.1384 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04855\n",
      "Epoch 101/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0917 - accuracy: 0.9780 - val_loss: 0.1934 - val_accuracy: 0.9623\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04855\n",
      "Epoch 102/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0469 - accuracy: 0.9864 - val_loss: 0.1839 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04855\n",
      "Epoch 103/150\n",
      "954/954 [==============================] - 6s 7ms/step - loss: 0.0277 - accuracy: 0.9885 - val_loss: 0.1626 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04855\n",
      "Epoch 104/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0157 - accuracy: 0.9906 - val_loss: 0.1166 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04855\n",
      "Epoch 105/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 0.1378 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04855\n",
      "Epoch 106/150\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.0439 - accuracy: 0.9853 - val_loss: 0.1742 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04855\n",
      "Epoch 107/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0186 - accuracy: 0.9927 - val_loss: 0.1467 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04855\n",
      "Epoch 108/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1634 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04855\n",
      "Epoch 109/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0477 - accuracy: 0.9937 - val_loss: 0.1115 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04855\n",
      "Epoch 110/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.1376 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04855\n",
      "Epoch 111/150\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.0413 - accuracy: 0.9843 - val_loss: 0.1493 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.04855\n",
      "Epoch 112/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0795 - accuracy: 0.9874 - val_loss: 0.1474 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04855\n",
      "Epoch 113/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0509 - accuracy: 0.9874 - val_loss: 0.1515 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04855\n",
      "Epoch 114/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0238 - accuracy: 0.9906 - val_loss: 0.1483 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04855\n",
      "Epoch 115/150\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.0243 - accuracy: 0.9906 - val_loss: 0.1384 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04855\n",
      "Epoch 116/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.1425 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04855\n",
      "Epoch 117/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.1527 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.04855\n",
      "Epoch 118/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.1435 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04855\n",
      "Epoch 119/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1463 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04855\n",
      "Epoch 120/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0118 - accuracy: 0.9937 - val_loss: 0.1487 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04855\n",
      "Epoch 121/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0121 - accuracy: 0.9927 - val_loss: 0.1921 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.04855\n",
      "Epoch 122/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0766 - accuracy: 0.9790 - val_loss: 0.2169 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04855\n",
      "Epoch 123/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.1847 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04855\n",
      "Epoch 124/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0191 - accuracy: 0.9958 - val_loss: 0.1330 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04855\n",
      "Epoch 125/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0112 - accuracy: 0.9948 - val_loss: 0.1286 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04855\n",
      "Epoch 126/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.1604 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.04855\n",
      "Epoch 127/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0413 - accuracy: 0.9843 - val_loss: 0.1705 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04855\n",
      "Epoch 128/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0916 - accuracy: 0.9759 - val_loss: 0.0629 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04855\n",
      "Epoch 129/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0366 - accuracy: 0.9895 - val_loss: 0.0937 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04855\n",
      "Epoch 130/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0424 - accuracy: 0.9969 - val_loss: 0.0862 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04855\n",
      "Epoch 131/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 0.1054 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.04855\n",
      "Epoch 132/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0108 - accuracy: 0.9948 - val_loss: 0.1312 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04855\n",
      "Epoch 133/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1198 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.04855\n",
      "Epoch 134/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0119 - accuracy: 0.9948 - val_loss: 0.1196 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04855\n",
      "Epoch 135/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1198 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04855\n",
      "Epoch 136/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.1070 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04855\n",
      "Epoch 137/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0647 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04855\n",
      "Epoch 138/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0423 - accuracy: 0.9916 - val_loss: 0.1887 - val_accuracy: 0.9591\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04855\n",
      "Epoch 139/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0894 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04855\n",
      "Epoch 140/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0815 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04855\n",
      "Epoch 141/150\n",
      "954/954 [==============================] - 7s 8ms/step - loss: 0.0215 - accuracy: 0.9958 - val_loss: 0.0969 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04855\n",
      "Epoch 142/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.0974 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04855\n",
      "Epoch 143/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0711 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.04855\n",
      "Epoch 144/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0888 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04855\n",
      "Epoch 145/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0699 - val_accuracy: 0.9874\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04855\n",
      "Epoch 146/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0914 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04855\n",
      "Epoch 147/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1113 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04855\n",
      "Epoch 148/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.3040 - val_accuracy: 0.9686\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04855\n",
      "Epoch 149/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.1514 - accuracy: 0.9706 - val_loss: 0.1796 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04855\n",
      "Epoch 150/150\n",
      "954/954 [==============================] - 7s 7ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.1865 - val_accuracy: 0.9811\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.04855\n",
      "Training completed in time:  0:15:55.220900\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 150\n",
    "num_batch_size = 8 # Arbitrarily chose the value 8\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "# Train the model for a fix number of epochs\n",
    "# validation_data - data to evaluate the loss at the end of each epoch\n",
    "# callbacks - display ModelCheckpoint\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model using training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  99.58071112632751 %\n",
      "Testing Accuracy:  98.11320900917053 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1]*100, \"%\")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model using various audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MFCC values of Longer Vs. Shorter Samples\n",
    "# Creating a function that extracts the MFCC features of an audio file\n",
    "def extract_features(file_name, max_pad_len):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Librosa extraction of audio array and sampling rate\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # resampling at a \"faster rate as opposed to higher quality\"\n",
    "        \n",
    "        display(audio)\n",
    "        # MFCC feature extraction of audio - mfccs is mfcc sequence (array), n_mfcc is number of MFCCs to return\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        # If the number of frames is less than the max_pad_len, zero-pad up to max_pad_len\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file \", file_name)\n",
    "        return None\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_prediction(file_name, max_pad_length):\n",
    "    prediction_feature = extract_features(file_name, max_pad_length)\n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating a few UrbanSound8k datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00010893, -0.00017632, -0.00017818, ..., -0.04449912,\n",
       "       -0.04784342, -0.04944142], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n",
      "car_horn \t\t :  0.00010090511204907670617103576660\n",
      "gun_shot \t\t :  0.92070323228836059570312500000000\n",
      "siren \t\t :  0.07919595390558242797851562500000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01967856, -0.00505069, -0.06804643, ..., -0.03580907,\n",
       "        0.09565555,  0.19201374], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n",
      "car_horn \t\t :  0.00000000000000062305191913272729\n",
      "gun_shot \t\t :  0.00000000000019068333880194882068\n",
      "siren \t\t :  1.00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "import os\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "\n",
    "root_path = Path(os.getcwd()).parent.parent # Software Folder\n",
    "\n",
    "# Random gun shot file file\n",
    "filename = root_path / \"Training_Dataset\" / \"audio\" / \"fold6\" /  \"135544-6-4-0.wav\"\n",
    "print_prediction(filename, max_pad_length)\n",
    "\n",
    "# Siren file\n",
    "filename = root_path / \"Training_Dataset\" / \"audio\" / \"fold3\" /  \"184623-8-0-1.wav\"\n",
    "print_prediction(filename, max_pad_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tesing using microphone array recordings\n",
    "###### **Envionment: EPH 425**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the prediction for the gunshot\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00398104,  0.0070504 , -0.01208133, ..., -0.09954793,\n",
       "       -0.10348408, -0.10246389], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n",
      "car_horn \t\t :  0.00224094279110431671142578125000\n",
      "gun_shot \t\t :  0.92459446191787719726562500000000\n",
      "siren \t\t :  0.07316459715366363525390625000000\n",
      "Below is the prediction for the carhorn\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00395943,  0.0063127 , -0.00976675, ...,  0.04595372,\n",
       "        0.04855135,  0.07447524], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "car_horn \t\t :  0.99265444278717041015625000000000\n",
      "gun_shot \t\t :  0.00685489876195788383483886718750\n",
      "siren \t\t :  0.00049061636673286557197570800781\n",
      "Below is the prediction for the siren\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.72825736, -1.072797  , -0.9774418 , ...,  0.81695753,\n",
       "        1.075544  ,  0.9845603 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n",
      "car_horn \t\t :  0.00000000037067890423791993725899\n",
      "gun_shot \t\t :  0.00000000000000000000037864351574\n",
      "siren \t\t :  1.00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "root_path = Path(os.getcwd()).parent.parent # Software Folder\n",
    "\n",
    "gun_mic = root_path / \"Testing_Dataset\" / \"Different_env\" / \"gunshot_micarray.wav\"\n",
    "car_mic = root_path / \"Testing_Dataset\" / \"Different_env\" / \"carhorn_micarray.wav\"\n",
    "siren_mic = root_path / \"Testing_Dataset\" / \"Different_env\" / \"siren_micarray.wav\"\n",
    "\n",
    "print(\"Below is the prediction for the gunshot\\n\")\n",
    "print_prediction(gun_mic, max_pad_length)\n",
    "\n",
    "print(\"Below is the prediction for the carhorn\\n\") \n",
    "print_prediction(car_mic, max_pad_length)\n",
    "\n",
    "print(\"Below is the prediction for the siren\\n\") \n",
    "print_prediction(siren_mic, max_pad_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iPhone Microphone testing for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the prediction for the GUNSHOT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.00044385, 0.00059537,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "car_horn \t\t :  1.00000000000000000000000000000000\n",
      "gun_shot \t\t :  0.00000000000007144749337517977694\n",
      "siren \t\t :  0.00000000000000000000000006288511\n",
      "Below is the prediction for the SIREN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.15548964, -0.09063674,  0.12174813, ..., -0.19627422,\n",
       "       -0.19866323,  0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n",
      "car_horn \t\t :  0.00000000000000001190630786973211\n",
      "gun_shot \t\t :  0.00000000000005240817477799968038\n",
      "siren \t\t :  1.00000000000000000000000000000000\n",
      "Below is the prediction for the CARHORN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ..., -0.00020375,\n",
       "       -0.00019858,  0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "car_horn \t\t :  0.99999964237213134765625000000000\n",
      "gun_shot \t\t :  0.00000037998506741132587194442749\n",
      "siren \t\t :  0.00000000000000000000000000030553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_path = Path(os.getcwd()).parent.parent # Software Folder\n",
    "\n",
    "gunshot = root_path / \"Testing_Dataset\" / \"iPhone_data\" / \"gunShot.wav\"\n",
    "\n",
    "siren = root_path / \"Testing_Dataset\" / \"iPhone_data\" / \"siren.wav\"\n",
    "\n",
    "carhorn = root_path / \"Testing_Dataset\" / \"iPhone_data\" / \"carHorn.wav\"\n",
    "\n",
    "print(\"\\nBelow is the prediction for the GUNSHOT\\n\")\n",
    "print_prediction(gunshot, max_pad_length)\n",
    "\n",
    "print(\"\\nBelow is the prediction for the SIREN\\n\")\n",
    "print_prediction(siren, max_pad_length)\n",
    "\n",
    "print(\"\\nBelow is the prediction for the CARHORN\\n\")\n",
    "print_prediction(carhorn, max_pad_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More testing conducted from recordings from the microphone array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the prediction for the GUNSHOT\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00132929, 0.01123005, 0.01600517, ..., 0.0115947 , 0.0059101 ,\n",
       "       0.00452592], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: gun_shot \n",
      "\n",
      "car_horn \t\t :  0.01004302036017179489135742187500\n",
      "gun_shot \t\t :  0.98989516496658325195312500000000\n",
      "siren \t\t :  0.00006183744699228554964065551758\n",
      "Below is the prediction for the SIREN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00168128, -0.00123748, -0.00409833, ..., -0.00118579,\n",
       "        0.00104005,  0.00092989], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n",
      "car_horn \t\t :  0.00000000000000296005806637558624\n",
      "gun_shot \t\t :  0.00000000000000769082199184381587\n",
      "siren \t\t :  1.00000000000000000000000000000000\n",
      "Below is the prediction for the CARHORN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00198785,  0.00100049,  0.00456577, ..., -0.00214608,\n",
       "        0.00849659,  0.00240523], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "car_horn \t\t :  1.00000000000000000000000000000000\n",
      "gun_shot \t\t :  0.00000004647453621942077006679028\n",
      "siren \t\t :  0.00000000017003706775930993444490\n",
      "THE PREDICTION BELOW IS THE FOREIGN SOUND RECORDED WITH THE MICROPHONE ARRAY\n",
      "\n",
      "We know the sound should be categorized to car horn\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01046848, 0.01890162, 0.02154594, ..., 0.0111305 , 0.00932156,\n",
       "       0.00921465], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: car_horn \n",
      "\n",
      "car_horn \t\t :  1.00000000000000000000000000000000\n",
      "gun_shot \t\t :  0.00000000000000000000000000000000\n",
      "siren \t\t :  0.00000000000000000000000000000000\n",
      "The prediction below is a foreign sound found on an online source\n",
      "\n",
      "We know the soudn should be categorized to siren\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.12262643, -0.13969955, -0.06495816, ...,  0.1658367 ,\n",
       "        0.11608469,  0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: siren \n",
      "\n",
      "car_horn \t\t :  0.00000000000000000000000000000000\n",
      "gun_shot \t\t :  0.00000000000000000000000000000000\n",
      "siren \t\t :  1.00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Victoria's testing for comparison\n",
    "\n",
    "root_path = Path(os.getcwd()).parent.parent # Software Folder\n",
    "\n",
    "gunshot = root_path / \"Testing_Dataset\" / \"Same_Env\" / \"gunshot.wav\"\n",
    "\n",
    "siren = root_path / \"Testing_Dataset\" / \"Same_Env\" / \"siren.wav\"\n",
    "\n",
    "carhorn = root_path / \"Testing_Dataset\" / \"Same_Env\" / \"carhorn.wav\"\n",
    "\n",
    "# Testing on another car horn sound recorded from microphone array from UrbanSound8k dataset\n",
    "videosound = root_path / \"Testing_Dataset\" / \"Same_Env\" / \"videoSound.wav\"\n",
    "\n",
    "# Tesing on random siren sound found on youtube\n",
    "youtube_sound = root_path / \"Testing_Dataset\" / \"Foreign_Data\" / \"siren_youtube.wav\"\n",
    "\n",
    "print(\"Below is the prediction for the GUNSHOT\\n\")\n",
    "print_prediction(gunshot, max_pad_length)\n",
    "\n",
    "print(\"Below is the prediction for the SIREN\\n\")\n",
    "print_prediction(siren, max_pad_length)\n",
    "\n",
    "print(\"Below is the prediction for the CARHORN\\n\")\n",
    "print_prediction(carhorn, max_pad_length)\n",
    "\n",
    "print(\"THE PREDICTION BELOW IS THE FOREIGN SOUND RECORDED WITH THE MICROPHONE ARRAY\\n\")\n",
    "print(\"We know the sound should be categorized to car horn\\n\")\n",
    "print_prediction(videosound, max_pad_length)\n",
    "\n",
    "print(\"The prediction below is a foreign sound found on an online source\\n\")\n",
    "print(\"We know the soudn should be categorized to siren\\n\")\n",
    "print_prediction(youtube_sound, max_pad_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
