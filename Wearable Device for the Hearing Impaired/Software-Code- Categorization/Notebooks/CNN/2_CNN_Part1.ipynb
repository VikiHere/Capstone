{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Algorithm Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A convolutional neural network algorithm will be tested against the MLP algorithm in order to determine which model may contain better statistical results. Given the fact that we are dealing with Mel Frequency Cepstrum Coefficients, it is best to utilize a CNN algorithm as multiple coefficients will be able to exploit CNN's success in Image Processing capacities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MFCC values of Longer Vs. Shorter Samples\n",
    "# Creating a function that extracts the MFCC features of an audio file\n",
    "def extract_features(file_name, max_pad_len):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Librosa extraction of audio array and sampling rate\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # resampling at a \"faster rate as opposed to higher quality\"\n",
    "        # MFCC feature extraction of audio - mfccs is mfcc sequence (array), n_mfcc is number of MFCCs to return\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        # If the number of frames is less than the max_pad_len, zero-pad up to max_pad_len\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file \", file_name)\n",
    "        return None\n",
    "    \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, in order to prepare our model, we need features to be extracted from all our audio signals for analysis. These features will be the input to the CNN algorithm that we train the model using. \n",
    "#### Before the features can be extracted, it's important to know the maximum number of frames when we extract MFCC's using the Librosa library in Python\n",
    "#### Below, we will be appending the lenVars list in order to extract the maximum number of frames in the portion of the dataset that we are interested in. We assign this to the variable max_pad_length as this will be directly used to extract features using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the path to the full UrbanSound dataset\n",
    "root_path = Path(os.getcwd()).parent.parent # Software Folder\n",
    "fulldatasetpath = root_path / \"Training_Dataset\" / \"audio\"\n",
    "metadata = pd.read_csv(root_path / \"Training_Dataset\" / \"metadata\" / \"MasterDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['car_horn', 'gun_shot', 'siren']\n",
    "\n",
    "lenVars = []\n",
    "\n",
    "# Iterate through each sound file and extract the number of frames \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    # Extract filename and category\n",
    "    #print(row[\"class_name\"])\n",
    "    category_str = row[\"class_name\"]\n",
    "    \n",
    "    # Loop through metadata comparing the categories\n",
    "    if category_str in categories:\n",
    "        # Extract MFCCs \n",
    "        file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "        file_name = Path(file_name) #Convert to pathlib object for OS compatibility\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs_pre = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        numFrames = mfccs_pre.shape[1]\n",
    "        lenVars.append(numFrames)\n",
    "            \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Extract max number of frames\n",
    "max_pad_length = max(lenVars)\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    # Extract filename and category\n",
    "    category_str = row[\"class_name\"]\n",
    "    \n",
    "    # Loop through metadata comparing the categories\n",
    "    if category_str in categories:\n",
    "    \n",
    "        file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "        class_label = row[\"class_name\"]\n",
    "        data = extract_features(file_name, max_pad_length)\n",
    "        features.append([data, class_label])\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that the maximum padding length has been found to be 173, this value can be inserted in the extract_features function as we iterate through the metadata to find the location of the sound files of interest, followed by a feature extraction of those files.\n",
    "#### The results are appended to a features array along with their respective categories. Ultimately this is translated to a dataframe in order to exploit the Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At the termination of this point, we have extracted our final feature count (1307 files) using the dataframe for features generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataframe such that there are the same number of files per class_label\n",
    "# This ensures that no one category has an advantage when the model is being trained\n",
    "\n",
    "print(featuresdf.class_label.count()) # 1307\n",
    "\n",
    "# Create dictionary of dataframes\n",
    "frames = {}\n",
    "categories = ['car_horn', 'gun_shot', 'siren']\n",
    "\n",
    "arr_Size = []\n",
    "\n",
    "for label in categories:\n",
    "    frames[label] = featuresdf[featuresdf['class_label'] == label]\n",
    "    # Extract shape and get number of rows\n",
    "    rNc = frames[label].shape\n",
    "    # Gets number of rows\n",
    "    arr_Size.append(rNc[0])\n",
    "    print(label, rNc[0])\n",
    "\n",
    "# Take the minimum size from size array\n",
    "minSize = min(arr_Size)\n",
    "\n",
    "# Utilize minimum size to slice rows such that only the minimum size is maintained\n",
    "for label in frames:\n",
    "    frames[label] = frames[label].sample(minSize)\n",
    "    print(frames[label].shape[0])\n",
    "    \n",
    "# Concatenate all dataframes in dictionary of dataframes\n",
    "# Place the concatenated frame back in featuresdf\n",
    "# Reindex\n",
    "result = pd.concat(frames)\n",
    "features_temp = pd.DataFrame()\n",
    "features_temp = result[[\"feature\", \"class_label\"]]\n",
    "\n",
    "# Reindex features_temp\n",
    "features_temp = features_temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At the termination of this point, we have extracted our final feature count using the dataframe for features generated above.\n",
    "#### Now, we came to realize that the number of files for the 3 categories of interest varied across the dataset: as seen above, car horn has 434 files, gun shot has 449 files and siren has 424 files. \n",
    "#### As such, in order to normalize this, we will find the category with the least number of samples and cut down the samples across all categories to that value.\n",
    "#### The cut down dataframe includes the same number of samples across all categories (424 files) and will be used for the actual model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send temp features to features df\n",
    "featuresdf = features_temp\n",
    "display(featuresdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the section below, the features dataframe above was utilized to extract X and Y variables where X is the features and Y corresponds to the category.\n",
    "#### In order to convert categories into numerical values for encoding, LabelEncoder from the sklearn.preprocessing followed by a binary matrix conversion\n",
    "#### The resultant data (features and encoded labels) was split into training and testing sets of 75% and 25%, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn.preprocessing.LabelEncoder to encode the categorical text data into model-understandable numerical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# This part will convert the categories into their respective numerical value\n",
    "le = LabelEncoder()\n",
    "# Fit transform receives categories and assigns numerical value to them. to_categorical converts to binary matrix\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# Split the dataset - 25% test, 75% train\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# X is feature, Y is labels\n",
    "# 42 is the seed to generating random numbers - starting position, integer required to ensure training and testing are consistent\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data into next notebook\n",
    "%store x_train\n",
    "%store x_test\n",
    "%store y_test\n",
    "%store y_train\n",
    "%store yy\n",
    "%store le\n",
    "%store max_pad_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
