{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "# x_train -  train samples: 2185\n",
    "# x_test - testing samples: 547\n",
    "# categories train: 2185\n",
    "# total samples\n",
    "\n",
    "# Retrieve previously stored variables\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "%store -r yy\n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "# Extract the number of labels - 4 in our case\n",
    "num_labels = yy.shape[1]\n",
    "\n",
    "# Begin constructing ML model\n",
    "# Create an object of the Sequential class\n",
    "model = Sequential()\n",
    "\n",
    "# Create input layer using the Dense function\n",
    "numNodes = 128; # Trial and error - 1/4 of 256 bit - went from 64 to 32 because size dropped from 2.7k to 1.4k\n",
    "numMFCC = 40;\n",
    "# Input shape is the size of the input array (1-D array of 40 columns, 1 row)\n",
    "model.add(Dense(numNodes, input_shape=(numMFCC,)));\n",
    "# Specifying the activation function to be used - relu: Rectified Linear Activiation\n",
    "model.add(Activation('relu'))\n",
    "# Dropout value of 50% - means random half of neurons exluded from each update cycle. Used to prevent overfitting.\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Add subsequest hidden layer - DENSE function\n",
    "model.add(Dense(numNodes))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the output layer - DENSE function\n",
    "# Output nodes is the different categories\n",
    "# Different usage of activation function\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# Optimizer \"adam\" is a typical optimizer used - variation SGD (stochastic gradient descent)\n",
    "# SGD utilizes the gradient of the loss function with respects to the weight\n",
    "# loss -> typical loss function \n",
    "# metrics is output to be displayed (accuracy is the output of the loss function (?))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               5248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 22,276\n",
      "Trainable params: 22,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 24.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.881140518188477, 0.23999999463558197]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "# Verbose - displays info if desired (verbose = 0 means silent, just print accuracy value)\n",
    "# evaluate returns loss value and score value\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "# Accuracy - the metrics value evaluated based on loss function\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)\n",
    "\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1346 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "1346/1346 [==============================] - 1s 497us/step - loss: 2.9457 - accuracy: 0.4762 - val_loss: 0.9602 - val_accuracy: 0.6133\n",
      "Epoch 2/100\n",
      "1346/1346 [==============================] - 1s 470us/step - loss: 1.8613 - accuracy: 0.4799 - val_loss: 1.0609 - val_accuracy: 0.5400\n",
      "Epoch 3/100\n",
      "1346/1346 [==============================] - 1s 437us/step - loss: 1.5280 - accuracy: 0.5022 - val_loss: 1.0593 - val_accuracy: 0.5200\n",
      "Epoch 4/100\n",
      "1346/1346 [==============================] - 1s 506us/step - loss: 1.2730 - accuracy: 0.5305 - val_loss: 1.0544 - val_accuracy: 0.5333\n",
      "Epoch 5/100\n",
      "1346/1346 [==============================] - 1s 482us/step - loss: 1.1188 - accuracy: 0.5319 - val_loss: 0.9872 - val_accuracy: 0.6133\n",
      "Epoch 6/100\n",
      "1346/1346 [==============================] - 1s 489us/step - loss: 1.0621 - accuracy: 0.5632 - val_loss: 0.9391 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "1346/1346 [==============================] - 1s 518us/step - loss: 1.0434 - accuracy: 0.5728 - val_loss: 0.9661 - val_accuracy: 0.5867\n",
      "Epoch 8/100\n",
      "1346/1346 [==============================] - 1s 638us/step - loss: 0.9578 - accuracy: 0.5884 - val_loss: 0.8732 - val_accuracy: 0.6533\n",
      "Epoch 9/100\n",
      "1346/1346 [==============================] - 1s 570us/step - loss: 0.9134 - accuracy: 0.6048 - val_loss: 0.8476 - val_accuracy: 0.6933\n",
      "Epoch 10/100\n",
      "1346/1346 [==============================] - 1s 967us/step - loss: 0.8767 - accuracy: 0.6211 - val_loss: 0.7877 - val_accuracy: 0.7200\n",
      "Epoch 11/100\n",
      "1346/1346 [==============================] - 2s 1ms/step - loss: 0.8870 - accuracy: 0.6248 - val_loss: 0.7611 - val_accuracy: 0.7533\n",
      "Epoch 12/100\n",
      "1346/1346 [==============================] - 1s 1ms/step - loss: 0.8169 - accuracy: 0.6568 - val_loss: 0.7182 - val_accuracy: 0.7467\n",
      "Epoch 13/100\n",
      "1346/1346 [==============================] - 1s 1ms/step - loss: 0.7847 - accuracy: 0.6716 - val_loss: 0.6779 - val_accuracy: 0.7467\n",
      "Epoch 14/100\n",
      "1346/1346 [==============================] - 1s 926us/step - loss: 0.7739 - accuracy: 0.6709 - val_loss: 0.6653 - val_accuracy: 0.7600\n",
      "Epoch 15/100\n",
      "1346/1346 [==============================] - 1s 857us/step - loss: 0.7582 - accuracy: 0.6716 - val_loss: 0.6575 - val_accuracy: 0.7933\n",
      "Epoch 16/100\n",
      "1346/1346 [==============================] - 2s 1ms/step - loss: 0.6907 - accuracy: 0.7177 - val_loss: 0.5950 - val_accuracy: 0.7933\n",
      "Epoch 17/100\n",
      "1346/1346 [==============================] - 2s 1ms/step - loss: 0.6761 - accuracy: 0.7155 - val_loss: 0.5581 - val_accuracy: 0.8067\n",
      "Epoch 18/100\n",
      "1346/1346 [==============================] - 2s 1ms/step - loss: 0.6499 - accuracy: 0.7147 - val_loss: 0.5130 - val_accuracy: 0.8200\n",
      "Epoch 19/100\n",
      "1346/1346 [==============================] - 1s 723us/step - loss: 0.6472 - accuracy: 0.7251 - val_loss: 0.5260 - val_accuracy: 0.8200\n",
      "Epoch 20/100\n",
      "1346/1346 [==============================] - 1s 919us/step - loss: 0.6519 - accuracy: 0.7273 - val_loss: 0.5417 - val_accuracy: 0.7733\n",
      "Epoch 21/100\n",
      "1346/1346 [==============================] - 1s 704us/step - loss: 0.6369 - accuracy: 0.7214 - val_loss: 0.5432 - val_accuracy: 0.7933\n",
      "Epoch 22/100\n",
      "1346/1346 [==============================] - 1s 683us/step - loss: 0.5991 - accuracy: 0.7489 - val_loss: 0.5048 - val_accuracy: 0.8533\n",
      "Epoch 23/100\n",
      "1346/1346 [==============================] - 1s 745us/step - loss: 0.5741 - accuracy: 0.7415 - val_loss: 0.4790 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "1346/1346 [==============================] - 1s 763us/step - loss: 0.5677 - accuracy: 0.7504 - val_loss: 0.4527 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "1346/1346 [==============================] - 1s 678us/step - loss: 0.5997 - accuracy: 0.7585 - val_loss: 0.4841 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "1346/1346 [==============================] - 1s 501us/step - loss: 0.5497 - accuracy: 0.7689 - val_loss: 0.4324 - val_accuracy: 0.8400\n",
      "Epoch 27/100\n",
      "1346/1346 [==============================] - 1s 439us/step - loss: 0.5534 - accuracy: 0.7689 - val_loss: 0.4217 - val_accuracy: 0.8667\n",
      "Epoch 28/100\n",
      "1346/1346 [==============================] - 1s 394us/step - loss: 0.5589 - accuracy: 0.7793 - val_loss: 0.4298 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "1346/1346 [==============================] - 1s 397us/step - loss: 0.5204 - accuracy: 0.7749 - val_loss: 0.4128 - val_accuracy: 0.8400\n",
      "Epoch 30/100\n",
      "1346/1346 [==============================] - 1s 406us/step - loss: 0.5289 - accuracy: 0.7949 - val_loss: 0.4123 - val_accuracy: 0.8200\n",
      "Epoch 31/100\n",
      "1346/1346 [==============================] - 1s 435us/step - loss: 0.4833 - accuracy: 0.7905 - val_loss: 0.3940 - val_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "1346/1346 [==============================] - 1s 584us/step - loss: 0.4848 - accuracy: 0.7972 - val_loss: 0.3985 - val_accuracy: 0.8533\n",
      "Epoch 33/100\n",
      "1346/1346 [==============================] - 1s 571us/step - loss: 0.4628 - accuracy: 0.8046 - val_loss: 0.3546 - val_accuracy: 0.8667\n",
      "Epoch 34/100\n",
      "1346/1346 [==============================] - 1s 461us/step - loss: 0.4683 - accuracy: 0.8076 - val_loss: 0.3929 - val_accuracy: 0.8533\n",
      "Epoch 35/100\n",
      "1346/1346 [==============================] - 1s 486us/step - loss: 0.4859 - accuracy: 0.7964 - val_loss: 0.3961 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "1346/1346 [==============================] - 1s 505us/step - loss: 0.4486 - accuracy: 0.8366 - val_loss: 0.3273 - val_accuracy: 0.8800\n",
      "Epoch 37/100\n",
      "1346/1346 [==============================] - 1s 445us/step - loss: 0.4520 - accuracy: 0.8120 - val_loss: 0.3663 - val_accuracy: 0.8733\n",
      "Epoch 38/100\n",
      "1346/1346 [==============================] - 1s 464us/step - loss: 0.4260 - accuracy: 0.8232 - val_loss: 0.3270 - val_accuracy: 0.8800\n",
      "Epoch 39/100\n",
      "1346/1346 [==============================] - 1s 522us/step - loss: 0.4244 - accuracy: 0.8343 - val_loss: 0.3529 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "1346/1346 [==============================] - 1s 518us/step - loss: 0.4088 - accuracy: 0.8321 - val_loss: 0.3451 - val_accuracy: 0.8933\n",
      "Epoch 41/100\n",
      "1346/1346 [==============================] - 1s 387us/step - loss: 0.4148 - accuracy: 0.8410 - val_loss: 0.3112 - val_accuracy: 0.9133\n",
      "Epoch 42/100\n",
      "1346/1346 [==============================] - 1s 427us/step - loss: 0.4134 - accuracy: 0.8425 - val_loss: 0.3159 - val_accuracy: 0.8600\n",
      "Epoch 43/100\n",
      "1346/1346 [==============================] - 1s 399us/step - loss: 0.4144 - accuracy: 0.8432 - val_loss: 0.3125 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "1346/1346 [==============================] - 1s 421us/step - loss: 0.4192 - accuracy: 0.8113 - val_loss: 0.3557 - val_accuracy: 0.8733\n",
      "Epoch 45/100\n",
      "1346/1346 [==============================] - 1s 409us/step - loss: 0.4077 - accuracy: 0.8276 - val_loss: 0.3526 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "1346/1346 [==============================] - 1s 424us/step - loss: 0.3986 - accuracy: 0.8388 - val_loss: 0.2889 - val_accuracy: 0.9067\n",
      "Epoch 47/100\n",
      "1346/1346 [==============================] - 1s 894us/step - loss: 0.3745 - accuracy: 0.8492 - val_loss: 0.3427 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "1346/1346 [==============================] - 1s 563us/step - loss: 0.3810 - accuracy: 0.8432 - val_loss: 0.2991 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "1346/1346 [==============================] - 1s 548us/step - loss: 0.3797 - accuracy: 0.8336 - val_loss: 0.3060 - val_accuracy: 0.8867\n",
      "Epoch 50/100\n",
      "1346/1346 [==============================] - 1s 557us/step - loss: 0.3937 - accuracy: 0.8291 - val_loss: 0.3126 - val_accuracy: 0.9000\n",
      "Epoch 51/100\n",
      "1346/1346 [==============================] - 1s 558us/step - loss: 0.3519 - accuracy: 0.8618 - val_loss: 0.3057 - val_accuracy: 0.8933\n",
      "Epoch 52/100\n",
      "1346/1346 [==============================] - 1s 490us/step - loss: 0.3381 - accuracy: 0.8633 - val_loss: 0.3212 - val_accuracy: 0.9067\n",
      "Epoch 53/100\n",
      "1346/1346 [==============================] - 1s 800us/step - loss: 0.3494 - accuracy: 0.8529 - val_loss: 0.2922 - val_accuracy: 0.9133\n",
      "Epoch 54/100\n",
      "1346/1346 [==============================] - 1s 1ms/step - loss: 0.3414 - accuracy: 0.8522 - val_loss: 0.2956 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "1346/1346 [==============================] - 1s 899us/step - loss: 0.3717 - accuracy: 0.8529 - val_loss: 0.2864 - val_accuracy: 0.9067\n",
      "Epoch 56/100\n",
      "1346/1346 [==============================] - 1s 642us/step - loss: 0.3400 - accuracy: 0.8685 - val_loss: 0.2857 - val_accuracy: 0.9200\n",
      "Epoch 57/100\n",
      "1346/1346 [==============================] - 1s 951us/step - loss: 0.3140 - accuracy: 0.8759 - val_loss: 0.3026 - val_accuracy: 0.9067\n",
      "Epoch 58/100\n",
      "1346/1346 [==============================] - 1s 811us/step - loss: 0.3288 - accuracy: 0.8722 - val_loss: 0.2828 - val_accuracy: 0.9067\n",
      "Epoch 59/100\n",
      "1346/1346 [==============================] - 1s 916us/step - loss: 0.3355 - accuracy: 0.8648 - val_loss: 0.2829 - val_accuracy: 0.9133\n",
      "Epoch 60/100\n",
      "1346/1346 [==============================] - 2s 1ms/step - loss: 0.3392 - accuracy: 0.8737 - val_loss: 0.2981 - val_accuracy: 0.8933\n",
      "Epoch 61/100\n",
      "1346/1346 [==============================] - 1s 852us/step - loss: 0.3254 - accuracy: 0.8685 - val_loss: 0.2683 - val_accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "1346/1346 [==============================] - 1s 708us/step - loss: 0.3515 - accuracy: 0.8722 - val_loss: 0.2830 - val_accuracy: 0.9267\n",
      "Epoch 63/100\n",
      "1346/1346 [==============================] - 1s 735us/step - loss: 0.3046 - accuracy: 0.8863 - val_loss: 0.2740 - val_accuracy: 0.9200\n",
      "Epoch 64/100\n",
      "1346/1346 [==============================] - 1s 724us/step - loss: 0.2942 - accuracy: 0.8930 - val_loss: 0.3021 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "1346/1346 [==============================] - 1s 603us/step - loss: 0.3001 - accuracy: 0.8826 - val_loss: 0.2426 - val_accuracy: 0.9467\n",
      "Epoch 66/100\n",
      "1346/1346 [==============================] - 1s 479us/step - loss: 0.2788 - accuracy: 0.8863 - val_loss: 0.2170 - val_accuracy: 0.9267\n",
      "Epoch 67/100\n",
      "1346/1346 [==============================] - 1s 538us/step - loss: 0.2856 - accuracy: 0.8826 - val_loss: 0.2889 - val_accuracy: 0.9200\n",
      "Epoch 68/100\n",
      "1346/1346 [==============================] - 1s 634us/step - loss: 0.2848 - accuracy: 0.8796 - val_loss: 0.2538 - val_accuracy: 0.9267\n",
      "Epoch 69/100\n",
      "1346/1346 [==============================] - 1s 468us/step - loss: 0.2903 - accuracy: 0.8871 - val_loss: 0.2736 - val_accuracy: 0.9267\n",
      "Epoch 70/100\n",
      "1346/1346 [==============================] - 1s 531us/step - loss: 0.3105 - accuracy: 0.8774 - val_loss: 0.2724 - val_accuracy: 0.9400\n",
      "Epoch 71/100\n",
      "1346/1346 [==============================] - 1s 504us/step - loss: 0.2911 - accuracy: 0.8908 - val_loss: 0.2711 - val_accuracy: 0.9267\n",
      "Epoch 72/100\n",
      "1346/1346 [==============================] - 1s 511us/step - loss: 0.2831 - accuracy: 0.8878 - val_loss: 0.2592 - val_accuracy: 0.9133\n",
      "Epoch 73/100\n",
      "1346/1346 [==============================] - 1s 799us/step - loss: 0.2817 - accuracy: 0.8848 - val_loss: 0.2235 - val_accuracy: 0.9200\n",
      "Epoch 74/100\n",
      "1346/1346 [==============================] - 1s 481us/step - loss: 0.2759 - accuracy: 0.8886 - val_loss: 0.2492 - val_accuracy: 0.9267\n",
      "Epoch 75/100\n",
      "1346/1346 [==============================] - 1s 506us/step - loss: 0.2614 - accuracy: 0.8938 - val_loss: 0.2800 - val_accuracy: 0.9067\n",
      "Epoch 76/100\n",
      "1346/1346 [==============================] - 1s 627us/step - loss: 0.2861 - accuracy: 0.8893 - val_loss: 0.2326 - val_accuracy: 0.9400\n",
      "Epoch 77/100\n",
      "1346/1346 [==============================] - 1s 827us/step - loss: 0.2681 - accuracy: 0.8960 - val_loss: 0.2234 - val_accuracy: 0.9467\n",
      "Epoch 78/100\n",
      "1346/1346 [==============================] - 1s 448us/step - loss: 0.2704 - accuracy: 0.8915 - val_loss: 0.2145 - val_accuracy: 0.9333\n",
      "Epoch 79/100\n",
      "1346/1346 [==============================] - 1s 524us/step - loss: 0.2729 - accuracy: 0.8893 - val_loss: 0.2412 - val_accuracy: 0.9200\n",
      "Epoch 80/100\n",
      "1346/1346 [==============================] - 1s 424us/step - loss: 0.2726 - accuracy: 0.8908 - val_loss: 0.2401 - val_accuracy: 0.9333\n",
      "Epoch 81/100\n",
      "1346/1346 [==============================] - 1s 597us/step - loss: 0.3010 - accuracy: 0.8863 - val_loss: 0.2387 - val_accuracy: 0.9200\n",
      "Epoch 82/100\n",
      "1346/1346 [==============================] - 1s 438us/step - loss: 0.2626 - accuracy: 0.8967 - val_loss: 0.2411 - val_accuracy: 0.9267\n",
      "Epoch 83/100\n",
      "1346/1346 [==============================] - 1s 470us/step - loss: 0.2495 - accuracy: 0.8945 - val_loss: 0.2399 - val_accuracy: 0.9267\n",
      "Epoch 84/100\n",
      "1346/1346 [==============================] - 1s 533us/step - loss: 0.2732 - accuracy: 0.8871 - val_loss: 0.2181 - val_accuracy: 0.9533\n",
      "Epoch 85/100\n",
      "1346/1346 [==============================] - 1s 447us/step - loss: 0.2357 - accuracy: 0.8997 - val_loss: 0.2290 - val_accuracy: 0.9333\n",
      "Epoch 86/100\n",
      "1346/1346 [==============================] - 1s 620us/step - loss: 0.2401 - accuracy: 0.9004 - val_loss: 0.2280 - val_accuracy: 0.9267\n",
      "Epoch 87/100\n",
      "1346/1346 [==============================] - 1s 691us/step - loss: 0.2518 - accuracy: 0.9034 - val_loss: 0.2340 - val_accuracy: 0.9400\n",
      "Epoch 88/100\n",
      "1346/1346 [==============================] - 1s 511us/step - loss: 0.2400 - accuracy: 0.9079 - val_loss: 0.2579 - val_accuracy: 0.9267\n",
      "Epoch 89/100\n",
      "1346/1346 [==============================] - 1s 555us/step - loss: 0.2499 - accuracy: 0.9138 - val_loss: 0.2859 - val_accuracy: 0.9067\n",
      "Epoch 90/100\n",
      "1346/1346 [==============================] - 1s 528us/step - loss: 0.2423 - accuracy: 0.9153 - val_loss: 0.2794 - val_accuracy: 0.9333\n",
      "Epoch 91/100\n",
      "1346/1346 [==============================] - 1s 660us/step - loss: 0.2477 - accuracy: 0.9049 - val_loss: 0.2145 - val_accuracy: 0.9400\n",
      "Epoch 92/100\n",
      "1346/1346 [==============================] - 1s 585us/step - loss: 0.2594 - accuracy: 0.9012 - val_loss: 0.2569 - val_accuracy: 0.9333\n",
      "Epoch 93/100\n",
      "1346/1346 [==============================] - 1s 500us/step - loss: 0.2912 - accuracy: 0.8997 - val_loss: 0.2375 - val_accuracy: 0.9267\n",
      "Epoch 94/100\n",
      "1346/1346 [==============================] - 1s 541us/step - loss: 0.2773 - accuracy: 0.8990 - val_loss: 0.2056 - val_accuracy: 0.9267\n",
      "Epoch 95/100\n",
      "1346/1346 [==============================] - 1s 442us/step - loss: 0.2449 - accuracy: 0.9116 - val_loss: 0.2124 - val_accuracy: 0.9400\n",
      "Epoch 96/100\n",
      "1346/1346 [==============================] - 1s 503us/step - loss: 0.2567 - accuracy: 0.9056 - val_loss: 0.2580 - val_accuracy: 0.9333\n",
      "Epoch 97/100\n",
      "1346/1346 [==============================] - 1s 709us/step - loss: 0.2511 - accuracy: 0.9094 - val_loss: 0.2311 - val_accuracy: 0.9400\n",
      "Epoch 98/100\n",
      "1346/1346 [==============================] - 1s 664us/step - loss: 0.2322 - accuracy: 0.9116 - val_loss: 0.2599 - val_accuracy: 0.9467\n",
      "Epoch 99/100\n",
      "1346/1346 [==============================] - 1s 531us/step - loss: 0.2344 - accuracy: 0.9064 - val_loss: 0.2475 - val_accuracy: 0.9400\n",
      "Epoch 100/100\n",
      "1346/1346 [==============================] - 1s 553us/step - loss: 0.2307 - accuracy: 0.9094 - val_loss: 0.2448 - val_accuracy: 0.9333\n",
      "Training completed in time:  0:01:25.625792\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 8 # Arbitrarily chose the value 8\n",
    "\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "# Train the model for a fix number of epochs\n",
    "# validation_data - data to evaluate the loss at the end of each epoch\n",
    "# callbacks - display ModelCheckpoint\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  96.28528952598572 %\n",
      "Testing Accuracy:  93.33333373069763 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1]*100, \"%\")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Creating a function that extracts the MFCC features of an audio file\n",
    "def extract_feature(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None, None\n",
    "\n",
    "    return np.array([mfccsscaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that will \n",
    "def print_prediction(file_name):\n",
    "    \n",
    "    # MFCCs of the specifc file contained in prediction_feature\n",
    "    prediction_feature = extract_feature(file_name)\n",
    "\n",
    "    # Directly maps to output\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    \n",
    "    # Inverse transform is used to convert encoded LabelEncoder() values back to strings\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    # Given new instance, model return probability (of belonging to each class) between 0 and 1 \n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    # Extract first array from array of arrays\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    \n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the prediction for a dog bark file\n",
      "The predicted class is: dog_bark \n",
      "\n",
      "car_horn \t\t :  0.00000000000000000000095449140306\n",
      "dog_bark \t\t :  1.00000000000000000000000000000000\n",
      "gun_shot \t\t :  0.00000000003150995783740562217190\n",
      "siren \t\t :  0.00000000000000000274229501612994\n",
      "\n",
      "Below is the prediction for a siren file\n",
      "The predicted class is: siren \n",
      "\n",
      "car_horn \t\t :  0.00000000000000000000000902081457\n",
      "dog_bark \t\t :  0.00000000001430626537374246609602\n",
      "gun_shot \t\t :  0.00000000000000000000000001330257\n",
      "siren \t\t :  1.00000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "root_path = Path(os.getcwd()).parent.parent # Software Folder\n",
    "\n",
    "# Random dog bark file\n",
    "filename = root_path / \"Training_Dataset\" / \"audio\" / \"fold1\" /  \"101415-3-0-2.wav\"\n",
    "print(\"Below is the prediction for a dog bark file\")\n",
    "print_prediction(filename)\n",
    "\n",
    "# Siren file\n",
    "#cwd = os.getcwd()\n",
    "filename = root_path / \"Training_Dataset\" / \"audio\" / \"fold3\" /  \"184623-8-0-1.wav\"\n",
    "print(\"\\nBelow is the prediction for a siren file\")\n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
